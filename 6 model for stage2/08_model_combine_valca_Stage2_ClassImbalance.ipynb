{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir ='/root/JupyterNotebook/kaggle-Redefining-Cancer-Treatment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_genevar = pd.read_csv(dir+'/4 input for stage2/training_variants.csv')\n",
    "target = train_genevar['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3689\n"
     ]
    }
   ],
   "source": [
    "train_len= len(target)\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_genevar = pd.read_csv(dir+'/4 input for stage2/test_variants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619\n"
     ]
    }
   ],
   "source": [
    "print(len(test_genevar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pid = test_genevar['ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_done = pickle.load(open(dir+'/5 middle for stage2/'+'onehotvar_cleantxt_data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_freq_allclass = pickle.load( open(dir+'/5 middle for stage2/'+'word_freq_all_data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_var_lst = pickle.load(open(dir+'/5 middle for stage2/'+'gen_var_lst', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = list(word_freq_allclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mylist = word_list+gen_var_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9698"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mylist = set(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_vocabulary = {}\n",
    "i = 0\n",
    "for word in mylist:\n",
    "    my_vocabulary[word] = i\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9250\n"
     ]
    }
   ],
   "source": [
    "print(len(my_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4308\n"
     ]
    }
   ],
   "source": [
    "print(len(df_done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traindata = df_done.iloc[:train_len]\n",
    "testdata = df_done.iloc[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, pipeline, feature_extraction, decomposition, model_selection, metrics, cross_validation, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import normalize, Imputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        x = x.drop(['CleanText'],axis=1).values\n",
    "        return x\n",
    "\n",
    "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        return x[self.key].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline...\n"
     ]
    }
   ],
   "source": [
    "print('Pipeline...')\n",
    "fp = pipeline.Pipeline([\n",
    "    ('union', pipeline.FeatureUnion(\n",
    "        n_jobs = -1,\n",
    "        transformer_list = [\n",
    "            ('pi3', pipeline.Pipeline([('CleanText', cust_txt_col('CleanText')), \n",
    "                                        ('hv', TfidfVectorizer(vocabulary=my_vocabulary)),\n",
    "                                    ])),\n",
    "            ('standard', cust_regression_vals())\n",
    "           \n",
    "        ])\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3689, 9319)\n"
     ]
    }
   ],
   "source": [
    "train = fp.fit_transform(traindata)\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 9319)\n"
     ]
    }
   ],
   "source": [
    "test = fp.transform(testdata).tocsc()\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = target -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.1538\tvalid-mlogloss:2.16213\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.07401\tvalid-mlogloss:1.36081\n",
      "[100]\ttrain-mlogloss:0.673685\tvalid-mlogloss:1.09757\n",
      "[150]\ttrain-mlogloss:0.47878\tvalid-mlogloss:0.988105\n",
      "[200]\ttrain-mlogloss:0.373627\tvalid-mlogloss:0.938538\n",
      "[250]\ttrain-mlogloss:0.30574\tvalid-mlogloss:0.916845\n",
      "[300]\ttrain-mlogloss:0.257987\tvalid-mlogloss:0.909957\n",
      "[350]\ttrain-mlogloss:0.222355\tvalid-mlogloss:0.908309\n",
      "[400]\ttrain-mlogloss:0.195539\tvalid-mlogloss:0.911889\n",
      "[450]\ttrain-mlogloss:0.172851\tvalid-mlogloss:0.917987\n",
      "Stopping. Best iteration:\n",
      "[352]\ttrain-mlogloss:0.221212\tvalid-mlogloss:0.908172\n",
      "\n",
      "0.90817159865\n",
      "[0]\ttrain-mlogloss:2.15382\tvalid-mlogloss:2.16185\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.07704\tvalid-mlogloss:1.32861\n",
      "[100]\ttrain-mlogloss:0.672818\tvalid-mlogloss:1.04425\n",
      "[150]\ttrain-mlogloss:0.475237\tvalid-mlogloss:0.925357\n",
      "[200]\ttrain-mlogloss:0.36656\tvalid-mlogloss:0.861559\n",
      "[250]\ttrain-mlogloss:0.30046\tvalid-mlogloss:0.830697\n",
      "[300]\ttrain-mlogloss:0.254744\tvalid-mlogloss:0.816271\n",
      "[350]\ttrain-mlogloss:0.221596\tvalid-mlogloss:0.810655\n",
      "[400]\ttrain-mlogloss:0.195334\tvalid-mlogloss:0.811682\n",
      "Stopping. Best iteration:\n",
      "[344]\ttrain-mlogloss:0.225095\tvalid-mlogloss:0.810397\n",
      "\n",
      "0.810397440339\n",
      "[0]\ttrain-mlogloss:2.1518\tvalid-mlogloss:2.16051\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.0765\tvalid-mlogloss:1.33411\n",
      "[100]\ttrain-mlogloss:0.681352\tvalid-mlogloss:1.05925\n",
      "[150]\ttrain-mlogloss:0.487717\tvalid-mlogloss:0.933287\n",
      "[200]\ttrain-mlogloss:0.382504\tvalid-mlogloss:0.873149\n",
      "[250]\ttrain-mlogloss:0.317124\tvalid-mlogloss:0.847087\n",
      "[300]\ttrain-mlogloss:0.267685\tvalid-mlogloss:0.832989\n",
      "[350]\ttrain-mlogloss:0.231664\tvalid-mlogloss:0.825677\n",
      "[400]\ttrain-mlogloss:0.204626\tvalid-mlogloss:0.825571\n",
      "[450]\ttrain-mlogloss:0.180998\tvalid-mlogloss:0.826885\n",
      "Stopping. Best iteration:\n",
      "[381]\ttrain-mlogloss:0.214734\tvalid-mlogloss:0.824921\n",
      "\n",
      "0.824920646355\n",
      "[0]\ttrain-mlogloss:2.15401\tvalid-mlogloss:2.16042\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.07303\tvalid-mlogloss:1.30439\n",
      "[100]\ttrain-mlogloss:0.676126\tvalid-mlogloss:1.02437\n",
      "[150]\ttrain-mlogloss:0.481453\tvalid-mlogloss:0.900917\n",
      "[200]\ttrain-mlogloss:0.374026\tvalid-mlogloss:0.843629\n",
      "[250]\ttrain-mlogloss:0.307958\tvalid-mlogloss:0.815343\n",
      "[300]\ttrain-mlogloss:0.260043\tvalid-mlogloss:0.80376\n",
      "[350]\ttrain-mlogloss:0.225407\tvalid-mlogloss:0.799517\n",
      "[400]\ttrain-mlogloss:0.198403\tvalid-mlogloss:0.798857\n",
      "[450]\ttrain-mlogloss:0.17651\tvalid-mlogloss:0.803621\n",
      "Stopping. Best iteration:\n",
      "[390]\ttrain-mlogloss:0.203205\tvalid-mlogloss:0.798195\n",
      "\n",
      "0.798194961083\n",
      "[0]\ttrain-mlogloss:2.15299\tvalid-mlogloss:2.1642\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.07328\tvalid-mlogloss:1.35034\n",
      "[100]\ttrain-mlogloss:0.670077\tvalid-mlogloss:1.08185\n",
      "[150]\ttrain-mlogloss:0.472701\tvalid-mlogloss:0.96199\n",
      "[200]\ttrain-mlogloss:0.365259\tvalid-mlogloss:0.90351\n",
      "[250]\ttrain-mlogloss:0.302016\tvalid-mlogloss:0.875741\n",
      "[300]\ttrain-mlogloss:0.256431\tvalid-mlogloss:0.861144\n",
      "[350]\ttrain-mlogloss:0.222088\tvalid-mlogloss:0.855409\n",
      "[400]\ttrain-mlogloss:0.19572\tvalid-mlogloss:0.85311\n",
      "[450]\ttrain-mlogloss:0.174494\tvalid-mlogloss:0.853612\n",
      "[500]\ttrain-mlogloss:0.156791\tvalid-mlogloss:0.855792\n",
      "Stopping. Best iteration:\n",
      "[433]\ttrain-mlogloss:0.181394\tvalid-mlogloss:0.852394\n",
      "\n",
      "0.852394208359\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "denom = 0\n",
    "fold = 5 #Change to 5, 1 for Kaggle Limits\n",
    "for i in range(fold):\n",
    "    params = {\n",
    "        'eta': 0.02,\n",
    "        'max_depth': 6,\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 9,\n",
    "        'seed': i,\n",
    "        'silent': True,\n",
    "        #new add\n",
    "        'max_delta_step':5,\n",
    "        'scale_pos_weight':10,\n",
    "    }\n",
    "    x1, x2, y1, y2 = train_test_split(train, y, test_size=0.15, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "    score1 = metrics.log_loss(y2, model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), labels = list(range(9)))\n",
    "    print(score1)\n",
    "    if denom != 0:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "        preds += pred\n",
    "    else:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "        preds = pred.copy()\n",
    "    denom += 1\n",
    "preds /= denom\n",
    "submission = pd.DataFrame(preds, columns=['class'+str(c+1) for c in range(9)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission['ID'] = pid\n",
    "submission.to_csv(dir+'/result/stage2/double_valca_e0.02_depth6_delta5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's multi_logloss: 1.3932 + 0.00881001\n",
      "[200]\tcv_agg's multi_logloss: 1.12378 + 0.0108234\n",
      "[300]\tcv_agg's multi_logloss: 0.998735 + 0.0111641\n",
      "[400]\tcv_agg's multi_logloss: 0.934519 + 0.0120051\n",
      "[500]\tcv_agg's multi_logloss: 0.900171 + 0.0127408\n",
      "[600]\tcv_agg's multi_logloss: 0.881366 + 0.0123839\n",
      "[700]\tcv_agg's multi_logloss: 0.87146 + 0.0118657\n",
      "[800]\tcv_agg's multi_logloss: 0.866593 + 0.0106844\n",
      "[900]\tcv_agg's multi_logloss: 0.864778 + 0.00919801\n",
      "num_boost_rounds_lgb=940\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "lgb_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 40, \n",
    "    'objective': 'multiclass',\n",
    "    'num_class':9,\n",
    "    'tree_learner':'voting',\n",
    "    'metric':'multi_logloss',\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'max_bin': 100}\n",
    "# form LightGBM datasets\n",
    "dtrain_lgb = lgb.Dataset(train, label=y)\n",
    "# LightGBM, cross-validation\n",
    "cv_result_lgb = lgb.cv(lgb_params, \n",
    "                       dtrain_lgb, \n",
    "                       num_boost_round=1000, \n",
    "                       nfold=5, \n",
    "                       stratified=True, \n",
    "                       early_stopping_rounds=50, \n",
    "                       verbose_eval=100, \n",
    "                       show_stdv=True)\n",
    "num_boost_rounds_lgb = len(cv_result_lgb['multi_logloss-mean'])\n",
    "print('num_boost_rounds_lgb=' + str(num_boost_rounds_lgb))\n",
    "# train model\n",
    "model_lgb = lgb.train(lgb_params, dtrain_lgb, num_boost_round=num_boost_rounds_lgb)\n",
    "y_pred=model_lgb.predict(test)\n",
    "classes = \"class1,class2,class3,class4,class5,class6,class7,class8,class9\".split(',')\n",
    "subm = pd.DataFrame(y_pred, columns=classes)\n",
    "subm['ID'] = pid\n",
    "\n",
    "subm.to_csv(dir+'/result/stage2/double_valca_lightgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 68.891s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "svd = decomposition.TruncatedSVD(n_components=300, n_iter=25, random_state=12)\n",
    "train_af = svd.fit_transform(train)\n",
    "print(\"done in %0.3fs\"%(time() - t0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.270s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()  \n",
    "test_af = svd.transform(test)  \n",
    "print(\"done in %0.3fs\"%(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_af = preprocessing.scale(train_af)\n",
    "test_af = preprocessing.scale(test_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1, x2, y1, y2 = train_test_split(train_af, y, test_size = 0.15, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf=svm.SVC(kernel='linear',probability=True,class_weight='balanced')\n",
    "\n",
    "clf.fit(x1,y1)\n",
    "\n",
    "print(clf.score(x2,y2))\n",
    "pred = clf.predict_proba(test_af)\n",
    "\n",
    "submission_svm = pd.DataFrame(pred, columns=['class'+str(c+1) for c in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_svm['ID'] = pid\n",
    "submission_svm.to_csv(dir+'/result/stage2/double_valca_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
